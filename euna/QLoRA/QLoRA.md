# QLoRA

논문 : https://arxiv.org/abs/2305.14314

LoRA의 확장된 기법으로, 모델의 가중치를 4비트로 양자화하여 메모리 사용량을 줄여 전이 학습을 수행.

## 양자화

모델의 가중치나 활성화 값을 더 적은 비트로 표현하는 방법.

모델의 파라미터를 더 낮은 비트 수로 표현

### 4비트 양자화

각 가중치 값을 4비트 (16개의 고정된 값으로 표현)로 반환.

실수로 표현된 가중치 값들을 16개의 이산 값으로 매핑하여 대략적으로 표현